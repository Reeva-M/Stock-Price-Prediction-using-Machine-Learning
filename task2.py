# -*- coding: utf-8 -*-
"""Task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T9OD7DHsbxoidP4gecmO3BZDScoaFyS0

> ML-Mini Project Task 2 \
(PreProcessing and EDA)

#Reeva Vijay Mishra _ 60009220203 _ D2-1 _ D093
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

df = pd.read_csv("/content/GOOGL.csv")

"""#Display the top 5 observations of the dataset

#Preprocessing
"""

df.head()

"""#Display the last 5 observations of the dataset"""

df.tail()

"""#The features that are used to analyze the stock’s performance over time:

---


**Date**: The date of the stock data
entry.


---


**Open**: The price of the stock at the beginning of the trading day.


---


**High**: The highest price of the stock during the trading day.


---


**Low**: The lowest price of the stock during the trading day.


---


**Close**: The price of the stock at the end of the trading day.


---


**Volume**: The number of shares traded during the trading day.


---


**Adjusted Close**: The closing price of the stock, adjusted for any corporate actions such as stock splits, dividends, and rights offerings.

#Understanding the data type and information about data, including the number of records in each column, data having null or not null, Data type, the memory usage of the dataset
"""

df.info()

"""#Several unique values in each column"""

df.nunique()

"""#Checking for duplicate values"""

df[df.duplicated()]

"""There are no duplicated values in my dataset.

#Summary of statistics pertaining to the DataFrame’s columns
"""

df.describe()

df['Volume'].value_counts()

df.isnull()

df.isnull().sum()

(df.isnull().sum()/(len(df)))*100

"""There are no null values either"""

output = []
for col in df.columns:
    unique = df[col].nunique()
    colType = str(df[col].dtype)
    categories=df[col].unique()

    output.append([col, unique, colType,categories])

output = pd.DataFrame(output)
output.columns = ['colName','unique','dtype','categories']
output

print(np.max(df['Volume']))
print(np.min(df['Volume']))

"""#Exploratory Data Analysis

**Scatter Plot**
"""

plt.scatter(df['Open'], df['Close'], color='purple')
plt.title('Scatter Plot of Google Stock Open vs Close Prices')
plt.xlabel('Open Price')
plt.ylabel('Close Price')
plt.show()

"""The scatter plot shows a strong positive correlation between the opening and closing prices of Google’s stock.

The upward slope of the data points indicates that as the opening price increases, the closing price tends to increase as well.

This suggests a consistent relationship between the two prices throughout the trading day.

Such a pattern is typical for stable stocks, where the opening and closing prices are often close to each other barring any major market events.

**Pie Chart**
"""

# Define a threshold for categorization
threshold = df['Close'].mean()

# Categorize days based on the 'Close' price
df['Category'] = df['Close'].apply(lambda x: 'Above Average' if x >= threshold else 'Below Average')

# Count the frequency of each category
category_counts = df['Category'].value_counts()

# Plot a pie chart
plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%')
plt.title('Pie Chart of Days Above and Below Average Close Price')
plt.show()

"""The pie chart indicates that a majority of the days, specifically 63.4%, had a closing price below the average, while 36.6% of days had a closing price above the average. \

This suggests that over the period represented in the dataset, Google’s stock closed more often below the average price point. \

Such information can be useful for investors looking to understand the stock’s performance and could potentially inform investment strategies.

**Histogram**
"""

df['Open'].plot(kind='hist', bins=20, title='Open', color='skyblue', edgecolor='black')
plt.gca().spines[['top', 'right',]].set_visible(False)

"""The histogram shows the distribution of the ‘Open’ prices for a dataset, presumably the Google stock data.

 The most frequent ‘Open’ price range is between 0 to 500, with the frequency peaking at over 1400 occurrences.

 This indicates that the stock opened within this price range on many occasions, suggesting a concentration of opening prices in the lower segment of the range provided.

 This histogram can help identify the most common price ranges the stock opens at, which can be useful for trend analysis and forecasting.

**Line Plot**
"""

from matplotlib import pyplot as plt
df['High'].plot(kind='line', figsize=(8, 4), title='High')
plt.gca().spines[['top', 'right']].set_visible(False)

"""The line graph indicates a significant upward trend in the “High” value of the stock over time, particularly after 2016, suggesting strong growth and an increasing peak stock price leading up to 2020.  

The flat trend prior to 2016 implies a period of relative stability. This kind of trend analysis is useful for understanding the stock’s historical performance and potential future trajectory.
"""

plt.plot(df['Date'], df['Close'])
plt.xlabel('Date')
plt.ylabel('Closing Price')
_ = plt.title('Closing Price Over Time')

"""The graph shows a significant increase in the closing price over time, particularly after 2018, we can infer that there was a period of substantial growth in the asset’s value during that time.  

The steady rise before 2018 suggests a more gradual growth, while the sharp increase after 2018 could indicate a bullish market trend or a response to specific events or conditions affecting the asset’s value.

**Violin Plot**
"""

figsize = (12, 1.2 * len(df['Category'].unique()))
plt.figure(figsize=figsize)
sns.violinplot(df, x='High', y='Category', inner='box', palette='Dark2')
sns.despine(top=True, right=True, bottom=True, left=True)

"""The graph indicates two distinct distributions for the categories “Below Average” and “Above Average” in terms of the ‘High’ value. \

The “Below Average” category is more narrowly distributed and centered around a lower value, while the “Above Average” category has a wider distribution and is centered around a higher value. \

This suggests variability within each category, with the “Above Average” category showing a broader range of ‘High’ values. Such a graph could be used to analyze the frequency of stock prices falling into these two categories over a certain period.

**Box Plot**
"""

plt.boxplot([df['Open'], df['High'], df['Low'], df['Close']], labels=['Open', 'High', 'Low', 'Close'])
plt.xlabel('Price Point')
plt.ylabel('Price')
_ = plt.title('Price Point Relationships')

"""The boxplot provides a visual summary of the distribution of data across the ‘Open’, ‘High’, ‘Low’, and ‘Close’ price points.

**Median Prices**: The median prices, indicated by the horizontal line within each box, are similar across all price points, suggesting a consistent central tendency.

**Interquartile Range (IQR)**: The size of the boxes, which represents the IQR, varies slightly, with the ‘High’ category having a slightly larger IQR, indicating more variability around the median.

This boxplot can help investors understand the typical price movements and variability of the stock, as well as identify any potential outliers that could indicate unusual market activity.

---


In order to be able to plot date on
x-axis we convert it to datetime


---
"""

df['Date'] = pd.to_datetime(df['Date'])

df[df.astype(str).apply(lambda x: x.str.contains("Below Average")).any(axis=1)]

"""

---


The heatmap cannot identify String values 'Below Average' and 'Above Average' therefore we replace it using np.nan


---

"""

df["Category"] = df["Category"].replace("Below Average", np.nan)
df["Category"] = df["Category"].replace("Above Average", np.nan)

"""**Heatmap**"""

sns.heatmap(df.corr(), annot=True)
plt.show()

"""The heatmap indicates the correlation between different stock-related variables such as Date, Open, High, Low, Close, Adjusted Close, and Volume.

**Strong Positive Correlation**: Most variables have a high positive correlation with each other, with values around 0.85 to 1, indicating that as one price point increases, the others tend to increase as well.\

**Volume’s Negative Correlation**: The Volume shows negative correlations with other variables, suggesting that as the Volume increases, the other variables tend to decrease, and vice versa.\

**Use in Analysis**: Such a heatmap is useful for identifying relationships between different aspects of stock data, which can be valuable for financial analysis and predictive modeling.

**StackPlot**
"""

plt.stackplot(df['Date'], df['Open'], df['High'], df['Low'], df['Close'])
plt.xlabel('Date')
plt.ylabel('Price')
_ = plt.legend(['Open', 'High', 'Low', 'Close'])

"""The stackplot illustrates the trends of Open, High, Low, and Close prices over time, from 2004 to 2022. \

The noticeable increase in all these prices around 2018 suggests a bullish market or increased value in the asset being represented. \

This type of visualization is helpful for understanding how different components contribute to the total and observing changes over time.  

The sharp rise after 2018 could indicate a period of significant growth or a market event that led to increased stock prices.

**Distplot**
"""

sns.distplot(df['Close'])
plt.show()

"""**Concentration of Data**: There’s a significant peak around the 0-500 range on the “Close” axis, suggesting that a large proportion of data points fall within this range.

**Density Estimate**: The blue line indicates a smoothed density estimate, peaking near 0 on the “Close” axis and tapering off, which implies that values near 0 are more frequent in the dataset.

**Histogram Bin**s: The blue bars represent histogram bins, showing frequency counts within specific ranges along the “Close” axis, corroborating the high concentration of data near the 0-500 range.

**PairPlot**
"""

sns.set_palette("hls")
sns.pairplot(df.drop(columns=['Category']))
plt.show()

"""**Positive Correlation**: The scatter plots show a strong positive correlation, indicating that as one variable increases, so does the other.

**Variable Distribution**: The histograms along the diagonal suggest varied distributions for the variables, with some displaying skewness and others appearing more uniform or normal.

This type of matrix is particularly useful for identifying patterns, trends, and potential areas of further statistical analysis, such as assessing multicollinearity or preparing data for machine learning models. The clear linear relationships suggest that these variables are likely to be predictive of each other, which could be valuable in building regression models or for feature selection in predictive analytics.

#Conclusion

In conclusion, our EDA has provided valuable insights into the stock price data, highlighting key trends and relationships. \

The preprocessing has ensured that the data is clean and ready for the next steps in the predictive modeling process.

 These efforts are essential in building a robust stock price prediction model that can help in making informed investment decisions.


---
"""